% \documentclass[anon]{colt2016} % Anonymized submission
\documentclass{colt2016} % Include author names

\usepackage[nolist]{acronym}
\usepackage{algorithm,algorithmic}
\usepackage{times}
\usepackage{enumerate}

\DeclareMathOperator{\Regret}{Regret}
\DeclareMathOperator{\Reward}{Reward}
\DeclareMathOperator{\polylog}{polylog}

\newcommand{\R}{\mathbb{R}}     % real numbers
\renewcommand{\H}{\mathcal{H}}  % Hilbert space
\newcommand{\KL}[2]{D\left({#1}\middle\|{#2}\right)}  % KL divergence
\newcommand{\norm}[1]{\left\|{#1}\right\|}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\indicator}{\mathbf{1}}

\begin{acronym}
\acro{OMD}{Online Mirror Descent}
\acro{OCO}{Online Convex Optimization}
\acro{OLO}{Online Linear Optimization}
\acro{LEA}{Learning with Expert Advice}
\end{acronym}

\coltauthor{%
   \Name{Francesco Orabona} \Email{francesco@orabona.com}\\
   \Name{D\'avid P\'al} \Email{dpal@yahoo-inc.com}\\
{\addr Yahoo Research, New York}
}

\title{Open Problem: Parameter-Free and Scale-Free Online Algorithms}

\begin{document}

\maketitle

\begin{abstract}
Existing vanilla algorithms for online linear optimization have
$O((\eta R(u) + 1/\eta) \sqrt{T})$ regret with respect to competitor $u$,
where $R(u)$ is a $1$-strongly convex regularizer and $\eta > 0$ is a
tuning parameter of the algorithm. For certain decision sets, the
so-called \emph{parameter-free} algorithms have been developed, which have
$\widetilde O(\sqrt{R(u) T})$ regret with respect to any competitor $u$.
Vanilla algorithm can achieve the same bound only for a fixed competitor
$u$ known ahead of time by setting $\eta = 1/\sqrt{R(u)}$. A drawback of
both vanilla and parameter-free algorithms is that they assume that loss vectors
have norms bounded by $1$. There exist \emph{scale-free} algorithms that have
$O((\eta R(u) + 1/\eta) \sqrt{T} \max_{1 \le t \le T} \norm{\ell_t})$
regret with respect to any competitor $u$ and for any sequence of loss
vector $\ell_1, \ell_2, \dots, \ell_T$. Parameter-free analogue of scale-free
algorithms have never been designed. Is is possible to design algorithms that
are both \emph{parameter-free} and \emph{scale-free} at the same time?
\end{abstract}

\section{Introduction}

Online linear optimization (OLO) is a sequential decision making problem where,
in each round $t$, an algorithm chooses a point $x_t$ from a convex
\emph{decision set} $K$ and then receives a loss vector $\ell_t$. Algorithm's
goal is to keep its cumulative loss $\sum_{t=1}^T \langle \ell_t, x_t \rangle$
small. Algorithm can be evaluated by comparing its loss with the loss of
hypothetical strategy that in every round chooses the same point $u$; the
difference of two losses is called \emph{regret}. More formally, \emph{regret
with respect to a competitor $u \in K$ after $T$ rounds} is
$$
\Regret_T(u) = \sum_{t=1}^T \langle \ell_t, x_t \rangle - \sum_{t=1}^T \langle \ell_t, u \rangle \; .
$$
For more details see~\cite{Cesa-Bianchi-Lugosi-2006, Shalev-Shwartz-2011}.

Algorithms for various decision sets have been investigated (the probability
simplex, various combinatorial polytopes, Hilbert space, unit ball in Hilbert
space). We focus on two particular sets, the $N$-dimensional probability
simplex $\Delta_N = \{ x \in \R^N ~:~ x \ge 0, \norm{x}_1 = 1\}$ and the
Hilbert space.\footnote{The particular type of Hilbert space does not play any
role. To fix ideas, consider the space of infinite sequences of real numbers
that are square-summable.} OLO over $\Delta_N$ is referred to as the problem of
Learning with Expert Advice (LEA); it used in machine learning as a way of
combining $N$ predictors and in boosting. OLO over Hilbert space is the
workhorse for learning of generalized linear models (e.g. logistic
regression, online SVM, linear least squares) in very high dimension.

We will use the following notation in the rest of this note. Shannon entropy
is $H(u) = -\sum_{i=1}^N u_i \ln u_i$ defined for any $u \in \Delta_N$. For any
$p \in [1,\infty]$, $\norm{\cdot}_p$ denotes $p$-norm in $\R^N$. If $\H$ is a
real Hilbert space, we denote by $\langle \cdot, \cdot \rangle$ its inner
product, and by $\norm{\cdot}$ the induced norm.

\section{Learning with Expert Advice}

Hedge algorithm~\citep{Freund-Schapire-1997} for LEA satisfies
\begin{equation}
\label{equation:hedge-bound}
\forall u \in \Delta_N \qquad \Regret_T(u) \le \sqrt{T \ln(N)}
\end{equation}
This bound is known to be optimal in the worst-case sense~\cite[Section
3.7]{Cesa-Bianchi-Lugosi-2006}. However, \eqref{equation:hedge-bound} has two
drawbacks.  First, the bound is independent of $u$. In other words, it does not
adapt to $u$.  Second, Hedge and the bound assume that $\ell_1, \ell_2, \dots,
\ell_T \in [0,1]^N$; we would like to allow loss vectors that are arbitary
vectors in $\R^N$.

Hedge is equivalent to Exponential Weights Algorithm (EWA).\footnote{Hedge is parametrized by $\beta \in (0,1)$ and EWA is parametrized by $\eta \in (0, \infty)$.
There is one-to-one correspondence, $\eta = - \ln \beta$, between the two algorithms.}
It can be shown that EWA with learning rate $\eta$, satisfies
\begin{equation}
\label{equation:hedge-bound-2}
\Regret_T(u) \le \frac{\ln N - H(u)}{\eta} + \eta T \; .
\end{equation}
Let $p \in [0, \ln N]$. If we choose $\eta = \sqrt{\frac{\ln(N) - p}{T}}$, we get that
\begin{equation}
\label{equation:hedge-bound-3}
\forall u \in \Delta_N, \qquad H(u) \ge p \quad \Longrightarrow \quad \Regret_T(u) \le \sqrt{T (\ln N - p)} \; .
\end{equation}
The bound \eqref{equation:hedge-bound} corresponds to choice $p=0$ and
$\eta=\sqrt{\frac{\ln N}{T}}$.

Instead of the family of bounds~\eqref{equation:hedge-bound-3} parametrized by
$p \in [0, \ln N]$ for a family of algorithms parametrized by $p$,
ideally, one would like to have a single algorithm (without any
tuning parameters) satisfying
\begin{equation}
\label{equation:parameter-free-bound-experts}
\forall u \in \Delta_N \qquad \Regret_T(u) \le \sqrt{T (\ln N - H(u))} \; .
\end{equation}

Bounds of the form~\eqref{equation:parameter-free-bound-experts} were not considered
until 2009. Since then, there have been a lot of work \citep{Chaudhuri-Freund-Hsu-2009,
Chernov-Vovk-2010, Koolen-van-Erven-2015, Luo-Schapire-2015, Foster-Rakhlin-Sridharan-2015,
Orabona-Pal-2016-parameter-free} on algorithms that
satisfy
\begin{equation}
\label{equation:parameter-free-bound-experts-2}
\forall u \in \Delta_N \qquad \Regret_T(u) \le \widetilde O(\sqrt{T (1 + \ln N - H(u))}) \; .
\end{equation}
Algorithms of this type are called \emph{parameter-free}, since in contrast to
Hedge/EWA, they do not need to know $p$.
They are sometime called algorithms for \emph{unknown number of
experts}, and~\eqref{equation:parameter-free-bound-experts-2} is called
called a \emph{quantile bound}. The reason for the latter name is that in order
to compete with $(\epsilon N)$-th best expert, on can choose competitor $u$ that
is uniform over the top $\epsilon N$ experts and has zero mass on the remaining experts.
In other words, up to permuation of coordinates, we consider competitor $u$ of the form
$$
u = \left( \frac{1}{\epsilon N}, \dots, \frac{1}{\epsilon N}, 0, \dots, 0 \right) \; .
$$
Such competitor satisfies $H(u) = \ln (\epsilon N)$ and regret with respect to
any such $u$ is $\widetilde O(\sqrt{T (1 + \ln(1/\epsilon)})$. In particular,
the last bound does not depend on the number of experts $N$, only on the
quantile $\epsilon$.  These algorithms remove the first drawback of Hedge.

The second drawback of Hedge is be removed by the AdaHedge algorithm of
\cite{de-Rooij-van-Erven-Grunwald-Koolen-2014}; see
also~\citep{Orabona-Pal-2016-parameter-free}. AdaHedge lifts the assumptions
$\ell_t \in [0,1]^N$. Namely, for any sequence of loss vectors
$\{\ell_t\}_{t=1}^\infty$, $\ell_t \in \R^N$, any $T \ge 0$ and any $u \in
\Delta_N$, AdaHedge satisfies $\Regret_T(u) \le \sqrt{\ln N \sum_{t=1}^T
\norm{\ell_t}_\infty^2}$. AdaHedge is \emph{scale-free} which means that its
predictions $x_t$ are the same for $\{\ell_t\}_{t=1}^\infty$ and $\{c
\ell_t\}_{t=1}^\infty$ where $c$ is any positive constant.

Our first open problem is to design an algorithm that combines the advatanges
of parameter-free and scale-free algorithms. More formally: \emph{Does there exist a universal constant $C > 0$
and, for each $N \ge 2$, is there an algorithm (without any tuning parameters) such that for any sequence of
loss vectors $\{\ell_t\}_{t=1}^\infty$, $\ell_t \in \R^N$,
$$
\forall T \ge 0 \quad \forall u \in \Delta_N \qquad \Regret_T(u) \le C \sqrt{(1 + \ln N - H(u)) \sum_{t=1}^T \norm{\ell_t}_\infty^2} \ \ ?
$$
}

\section{OLO over Hilbert Spaces}

The situation with algorithms for OLO over a Hilbert space $\H$ is very similar
to that of LEA.

The canonical algorithm is Follow The Regularized Leader (FTRL) algorithm\footnote{For constant learning rate, the algorithm is
equivalent to gradient descent. However, gradient descent is the ``wrong'' algorithm
for non-constant learning rates; see~\cite{Orabona-Pal-2016-scale-free}.}
with regularizer $\frac{1}{2}\|x\|^2$. The algorithm is parametrized by learning rate $\eta_t > 0$
that in round $t$ chooses
$$
x_t = \argmin_{x \in \H} \left( \frac{1}{2\eta_t}\|x\|^2 + \sum_{s=1}^{t-1} \langle \ell_t, x \rangle \right) \; .
$$
FTRL with constant learning rate $\eta_t = \eta$ satisfies
\begin{equation}
\label{equation:ftrl-vanila}
\forall u \in \H \qquad \Regret_T(u) \le \frac{1}{2} \left( \lambda + \frac{\norm{u}^2}{\lambda} \right) \sqrt{T} \; .
\end{equation}
assuming that $\norm{\ell_1}, \norm{\ell_2}, \dots, \norm{\ell_T} \le 1$.
Bound~\eqref{equation:ftrl-vanila} can be viewed as analogue of \eqref{equation:hedge-bound-2}.

We rewrite~\eqref{equation:ftrl-vanila} slighlty differently. For any $D \ge
0$, FTRL with learning rate $\eta_t = D/\sqrt{T}$, satisfies
\begin{equation}
\label{equation:ftrl-vanila-3}
\forall u \in \H \qquad \|u\| \le D \quad  \Longrightarrow \quad \Regret_T(u) \le D \sqrt{T} \; .
\end{equation}
Bound~\eqref{equation:ftrl-vanila-3} can be viewed as analogue of \eqref{equation:hedge-bound-3}.

a
More generally, for $\eta_t = \lambda/\sqrt{T}$, the algorithm satisfies
$$
\forall u \in \H \qquad \Regret_T(u) \le \frac{1}{2}(1 + \norm{u}^2) \sqrt{T} \; .
$$
From this we can derive that,  with $\eta_t = \lambda/\sqrt{T}$,
 the algorithm

Given $\eta > 0$, FTRL with the same regularizer and
learning rate $\eta/\sqrt{T}$ satisfies $\Regret_T(u) \le \eta \sqrt{T}$
for all $u$ such that $\norm{u} \le \eta$. Thus, effectively replacing
$\frac{1}{2}(1 + \norm{u}^2)$ with $\eta \ge \norm{u}$.

There have been a lot of work \citep{Streeter-McMahan-2012, Orabona-2013,
McMahan-Abernethy-2013, McMahan-Orabona-2014} on algorithms that satisfy
$\Regret_T(u) \le \widetilde O(\sqrt{\norm{u} T})$ for all $u \in \H$.
The $\widetilde O$ notation hides poly-logarithmic factors in $\norm{u}$ and
$T$. These are called \emph{parameter-free} algorithms, since they do not need to
know $\eta$.

\emph{Scale-free} version of FTRL with the same regularizer but with learning
rate $1/\sqrt{\sum_{i=1}^{t-1} \norm{\ell_i}^2}$ satisfies $\Regret_T(u) \le
(6.25 + \frac{1}{2}\norm{u}^2) \sqrt{T} \max_{1 \le t \le T} \norm{\ell_t}$ for
any $T \ge 0$ and any sequence of loss vectors $\{\ell_t\}_{t=1}^\infty$~\citep{Orabona-Pal-2015}. With learning
rate $\eta/\sqrt{\sum_{i=1}^{t-1} \norm{\ell_i}^2}$, the algorithm satisfies
$\Regret_T(u) \le 3.6 \norm{u} \sqrt{T} \max_{1 \le t \le T} \norm{\ell_t}$ for
all $u \in \H$ such that $\norm{u} \le \eta$. However for that the knowledge
of $\eta$ is required.

Our second open problem is to design an algorithm that for any
sequence of loss vectors $\{\ell_t\}_{t=1}^\infty$, any $T \ge 0$,
and any $u \in \H$ satisfies
$$
\Regret_T(u) \le \polylog(1 + \norm{u}, T) \cdot (1 + \norm{u}) \sqrt{T} \max_{1 \le t \le T} \norm{\ell_t} \; ,
$$
where $\polylog(1 + \norm{u}, T)$ is a function that is bounded by a polynomial
of $\log(1 + \norm{u})$ and $\log T$.

\bibliography{biblio}

\appendix

\section{Follow The Regularized Leader for Hilbert Space}

Let $L_t = \sum_{i=1}^t \ell_i$.
Follow The Regularized Leader with learning rate $\eta' > 0$ and regularizer $\frac{1}{2}\norm{w}^2$
chooses in round $t$,
$$
w_t
= \argmin_{w \in \H} \left( \frac{1}{2}\norm{w}^2 + \eta' \sum_{i=1}^{t-1} \langle \ell_i, w \rangle \right)
= - \eta' \sum_{i=1}^{t-1} \ell_i = - \eta' L_{t-1} \; .
$$

Since $\frac{1}{2}\norm{a-b}^2 \ge 0$ for any $a,b \in \H$, we have $\frac{1}{2}\norm{a}^2 \ge \langle a, b \rangle - \frac{1}{2}\norm{b}^2$.
Plugging $a = -\sqrt{\eta'} L_T$ and $b = u/\sqrt{\eta'}$, we have
$$
\frac{1}{2\eta'} \norm{u}^2 + \frac{\eta'}{2} \sum_{t=1}^T \norm{L_t}^2 - \norm{L_{t-1}}^2
= \frac{1}{2\eta'} \norm{u}^2 + \frac{\eta'}{2} \norm{L_T}^2  \ge - \langle L_T, u \rangle
= - \sum_{t=1}^T \langle \ell_t, u \rangle  \; .
$$
Adding $\sum_{t=1}^T \langle \ell_t, w_t \rangle$ to both sides, we have
$$
\Regret_T(u) \le \frac{1}{2\eta'} \norm{u}^2 + \frac{\eta'}{2} \sum_{t=1}^T \norm{L_t}^2 - \norm{L_{t-1}}^2 + \sum_{t=1}^T \langle \ell_t, w_t \rangle \; .
$$
Substuting $w_t = -\eta' L_{t-1}$ and $\norm{L_{t}}^2 = \norm{L_{t-1} + \ell_t}^2 = \norm{L_{t-1}}^2 + \norm{\ell_t}^2 + 2 \langle \ell_t, L_{t-1} \rangle$,
we have
$$
\Regret_T(u) \le \frac{1}{2\eta'} \norm{u}^2 + \frac{\eta'}{2} \sum_{t=1}^T \norm{\ell_t}^2 \; .
$$
Assuming $\norm{\ell_t} \le 1$ and $\eta' = \eta/\sqrt{T}$, we have
$$
\Regret_T(u) \le \left(\frac{1}{2\eta} \norm{u}^2 + \frac{\eta}{2} \right) \sqrt{T} \; .
$$


\end{document}
