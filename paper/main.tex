\documentclass{colt2016} % Include author names

\usepackage[nolist]{acronym}
\usepackage{algorithm,algorithmic}
\usepackage{times}
\usepackage{enumerate}

\DeclareMathOperator{\Regret}{Regret}
\DeclareMathOperator{\polylog}{polylog}

\newcommand{\R}{\mathbb{R}}     % real numbers
\renewcommand{\H}{\mathcal{H}}  % Hilbert space
\newcommand{\KL}[2]{D\left({#1}\middle\|{#2}\right)}  % KL divergence
\newcommand{\norm}[1]{\left\|{#1}\right\|}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\indicator}{\mathbf{1}}

\coltauthor{%
   \Name{Francesco Orabona} \Email{francesco@orabona.com}\\
   \Name{D\'avid P\'al} \Email{dpal@yahoo-inc.com}\\
{\addr Yahoo Research, New York}
}

\title{Open Problem: Parameter-Free and Scale-Free Online Algorithms}

\begin{document}

\maketitle

\begin{abstract}
Existing vanilla algorithms for online linear optimization have $O((\eta R(u) +
1/\eta) \sqrt{T})$ regret with respect to any competitor $u$, where $R(u)$ is a
$1$-strongly convex regularizer and $\eta > 0$ is a tuning parameter of the
algorithm. For certain decision sets and regularizers, the so-called
\emph{parameter-free} algorithms have $\widetilde O(\sqrt{R(u) T})$ regret with
respect to any competitor $u$.  Vanilla algorithm can achieve the same bound
only for a fixed competitor $u$ known ahead of time by setting $\eta =
1/\sqrt{R(u)}$. A drawback of both vanilla and parameter-free algorithms is
that they assume that the norm of the loss vectors is bounded by a constant
known to the algorithm. There exist \emph{scale-free} algorithms that have
$O((\eta R(u) + 1/\eta) \sqrt{T} \max_{1 \le t \le T} \norm{\ell_t})$ regret
with respect to any competitor $u$ and for any sequence of loss vector $\ell_1,
\dots, \ell_T$. Parameter-free analogue of scale-free algorithms have never
been designed. Is is possible to design algorithms that are simultaneously
\emph{parameter-free} and \emph{scale-free}?
\end{abstract}

\section{Introduction}

We consider the standard Online Linear Optimization
(OLO)~\citep{Cesa-Bianchi-Lugosi-2006, Shalev-Shwartz-2011} setting. In each
round $t$, an algorithm chooses a point $x_t$ from a convex \emph{decision set}
$K$ and then receives a loss vector $\ell_t$. Regret of the algorithm w.r.t. $u
\in K$ is $\Regret_T(u) = \sum_{t=1}^T \langle \ell_t, x_t \rangle -
\sum_{t=1}^T \langle \ell_t, u \rangle$. The goal of the algorithm is to keep
the regret small.

We focus on two particular sets, the $N$-dimensional probability simplex
$\Delta_N = \{ x \in \R^N ~:~ x \ge 0, \norm{x}_1 = 1\}$ and the Hilbert space.
OLO over $\Delta_N$ is referred to as the problem of Learning with Expert
Advice (LEA).

\textbf{Notation and preliminaries:} We denote by
$\indicator$ the vector $(1,1,\dots,1) \in \R^N$. Shannon entropy $H(u) =
-\sum_{i=1}^N u_i \ln u_i$ is defined for any $u \in \Delta_N$.  The
Kullback-Leibler divergence $\KL{u}{v} = \sum_{i=1}^N u_i \ln(u_i/v_i)$ is
defined for any $u,v \in \Delta_N$. For any $p \in [1,\infty]$,
$\norm{\cdot}_p$ denotes $p$-norm in $\R^N$.  We denote by $\norm{\cdot}_*$ the
dual norm of a norm $\norm{\cdot}$.  If $\H$ is a real Hilbert space, we denote
by $\langle \cdot, \cdot \rangle$ its inner product, and by $\norm{\cdot}$ the
induced norm. The negative Shannon entropy, $-H(u)$,
defined on $\Delta_N$ is $1$-strongly convex with respect to $\norm{\cdot}_1$.
The dual norm of $\norm{\cdot}_1$ is $\norm{\cdot}_\infty$.  The function $R(u)
= \frac{1}{2}\norm{u}^2$ defined on Hilbert space with norm $\norm{\cdot}$ is
$1$-strongly convex with respect to $\norm{\cdot}$.

Follow The Regularized Leader (FTRL) algorithm with regularizer $R:K \to \R$
and \emph{learning rate} $\eta > 0$ in round $t$ chooses
$
x_t = \argmin_{x \in K} \left( \frac{1}{\eta} R(x) + \sum_{s=1}^{t-1} \langle \ell_s, x \rangle \right)
$.
The following theorem is a slight modification of \citet[Theorem 2.11]{Shalev-Shwartz-2011}.
\begin{theorem}[Regret of FTRL]
\label{theorem:ftrl-regret}
If $R:K \to \R$ is $1$-strongly convex function with respect a norm
$\norm{\cdot}$ then for any sequence $\{\ell_t\}_{t=1}^\infty$ such that
$\|\ell_t\|_* \le 1$, FTRL with learning rate $\eta$ satisfies
for all $T \ge 0$ and all $u \in K$,
$\Regret_T(u) \le \frac{R(u) - \inf_{v \in K} R(v)}{\eta} + \frac{\eta T}{2}$.
\end{theorem}

\section{Learning with Expert Advice}

Hedge algorithm~\citep{Freund-Schapire-1997} for LEA satisfies
\begin{equation}
\label{equation:hedge-bound}
\forall u \in \Delta_N \qquad \Regret_T(u) \le \sqrt{2 T \ln N}
\end{equation}
This bound is known to be optimal in the worst-case sense~\cite[Section
3.7]{Cesa-Bianchi-Lugosi-2006}. However, \eqref{equation:hedge-bound} has two
drawbacks.  First, the right-hand side of \eqref{equation:hedge-bound} is
independent of $u$, that is, the algorithm does not adapt to $u$.
Second, Hedge satisfies \eqref{equation:hedge-bound} only if $\ell_1, \ell_2,
\dots, \ell_T \in [-1,1]^N$. We would like to allow loss vectors that are
arbitrary vectors in $\R^N$.

Hedge is identical to FTRL with regularizer $R(u) = -H(u)$.
Theorem~\ref{theorem:ftrl-regret} implies that Hedge with learning rate $\eta$, satisfies
\begin{equation}
\label{equation:hedge-bound-2}
\Regret_T(u) \le \frac{\ln N - H(u)}{\eta} + \frac{\eta T}{2} = \frac{\KL{u}{\frac{1}{N}\indicator}}{\eta} + \frac{\eta T}{2} \; .
\end{equation}
Let $p \in [0, \ln N)$. If we choose $\eta = \sqrt{\frac{\ln(N) - p}{T}}$, we get that
\begin{equation}
\label{equation:hedge-bound-3}
\forall u \in \Delta_N, \qquad H(u) \ge p \quad \Longrightarrow \quad \Regret_T(u) \le \sqrt{2 T (\ln(N) - p)} \; .
\end{equation}
The bound \eqref{equation:hedge-bound} corresponds to choice $p=0$ and
$\eta=\sqrt{\frac{\ln N}{T}}$.

Instead of the family of algorithms parametrized by $p \in [0,\ln N)$ that
satisfy bound~\eqref{equation:hedge-bound-3}, one \emph{would like to have} a single
algorithm (without any tuning parameters) satisfying
\begin{equation}
\label{equation:parameter-free-bound-experts}
\forall u \in \Delta_N \qquad \Regret_T(u) \le \sqrt{2 T (\ln N - H(u))} = \sqrt{2T \cdot \KL{u}{\tfrac{1}{N} \indicator}} \; .
\end{equation}
Note that \eqref{equation:parameter-free-bound-experts} is stronger than
\eqref{equation:hedge-bound-3} in following the sense: A single algorithm
satisfying~\eqref{equation:parameter-free-bound-experts} implies
\eqref{equation:hedge-bound-3} for all $p$ simultaneously. However, a family
of algorithms $\{A_p ~:~ p \in [0,\ln N)\}$ parametrized by $p$ where $A_p$
satisfies \eqref{equation:hedge-bound-3}, does not yield a single
algorithm satisfying \eqref{equation:parameter-free-bound-experts}.

Bounds of the form~\eqref{equation:parameter-free-bound-experts} were not
considered until 2009. Since then, however, there have been a lot of work
\citep{Chaudhuri-Freund-Hsu-2009, Chernov-Vovk-2010, Koolen-van-Erven-2015,
Luo-Schapire-2014, Luo-Schapire-2015, Foster-Rakhlin-Sridharan-2015,
Orabona-Pal-2016-parameter-free} on algorithms that satisfy slightly
looser\footnote{Earlier papers have extra logarithmic factors.
\citet{Foster-Rakhlin-Sridharan-2015, Orabona-Pal-2016-parameter-free} have
a fixed multiplicative constant hidden in $\widetilde
O(\cdot)$} versions of~\eqref{equation:parameter-free-bound-experts}
\begin{equation}
\label{equation:parameter-free-bound-experts-2}
\forall u \in \Delta_N \qquad \Regret_T(u) \le \widetilde O(\sqrt{T (1 + \ln N - H(u))}) = \widetilde O\left(\sqrt{T \left(1 + \KL{u}{\tfrac{1}{N}\indicator} \right)} \right) \; .
\end{equation}
Algorithms of this type are called \emph{parameter-free} since, in contrast to
Hedge, they do not need to know $p$. The regret in
\eqref{equation:parameter-free-bound-experts} is called a \emph{quantile bound}
because one can bound the regret with respect to $(\epsilon N)$-th best expert
for any $\epsilon \in (0,1)$. Indeed, regret with respect to $(\epsilon N)$-th
best expert is upper bounded by the regret with respect to the average of the
top $\epsilon N$ experts, which can be expressed as the regret with respect to
a competitor $u$ that, up to permutation of coordinates, has the form
$u = \left( 1/(\epsilon N), \dots, 1/(\epsilon N), 0, \dots, 0 \right)$.
Such competitor satisfies $H(u) = \ln (\epsilon N)$ and the regret with respect
to any such $u$ is $\widetilde O(\sqrt{T (1 + \ln(1/\epsilon)})$. Namely, the
last bound does not depend on the number of experts $N$, only on the quantile
$\epsilon$.  These algorithms remove the first drawback of Hedge.

The second drawback of Hedge is removed by the AdaHedge algorithm due to
\cite{de-Rooij-van-Erven-Grunwald-Koolen-2014}; see
also~\citep{Orabona-Pal-2016-parameter-free}. AdaHedge lifts the assumption
$\ell_t \in [-1,1]^N$. Namely, for any sequence of loss vectors
$\{\ell_t\}_{t=1}^\infty$, $\ell_t \in \R^N$, any $T \ge 0$ and any $u \in
\Delta_N$, AdaHedge satisfies $\Regret_T(u) \le 5.3 \sqrt{\ln N \sum_{t=1}^T
\norm{\ell_t}_\infty^2}$. AdaHedge is \emph{scale-free} which means that its
predictions $x_t$ are the same for $\{\ell_t\}_{t=1}^\infty$ and $\{c
\ell_t\}_{t=1}^\infty$ where $c$ is any positive constant.

Our first open problem is to design an algorithm that combines the advantages
of parameter-free and scale-free algorithms. More formally: \emph{Does there
exist a universal constant $C > 0$ and, for each $N \ge 2$, is there an
algorithm (without any tuning parameters) that runs in $O(N)$ time per round
and satisfies, for any sequence of loss
vectors $\{\ell_t\}_{t=1}^\infty$, $\ell_t \in \R^N$,}
\begin{equation}
\forall T \ge 0 \quad \forall u \in \Delta_N \qquad \Regret_T(u) \le C \sqrt{(1 + \ln N - H(u)) \sum_{t=1}^T \norm{\ell_t}_\infty^2} \ \ ?
\end{equation}

Attempts to solve the open problem include all sorts of doubling tricks.
For example, algorithm could keep an upper bound $B_t$ on $\max_{1 \le i \le t}
\norm{\ell_i}_\infty$, for example, of the form $B_t = \norm{\ell_1} 2^k$
doubling whenever larger $\norm{\ell_t}_\infty$ is observed. However, resulting
regret bounds might depend on $\log_2 \left( \frac{\max_{1 \le t \le T}
\norm{\ell_t}_\infty}{\norm{\ell_1}_\infty} \right)$ which can be $\Omega(T)$
in the worst-case.

A more promising approach is to use infinitely many copies of AdaHedge with
learning rates $2^{-i}$, $i=1,2,\dots$, and combine their predictions using a
master AdaHedge with a certain non-uniform prior distribution. However, the
resulting algorithm runs in $\Theta(N \log \log N)$ time.

\section{OLO over Hilbert Spaces}

The situation with algorithms for OLO over a Hilbert space $\H$ is very similar
to that of LEA. FTRL with regularizer $\frac{1}{2}\norm{u}^2$ and learning rate
$\eta$ satisfies (cf. Theorem~\ref{theorem:ftrl-regret})
\begin{equation}
\label{equation:ftrl-vanila}
\forall u \in \H \qquad \Regret_T(u) \le \frac{\norm{u}^2}{2\eta} + \frac{\eta T}{2},
\end{equation}
assuming that $\norm{\ell_1}, \norm{\ell_2}, \dots, \norm{\ell_T} \le 1$.
Bound~\eqref{equation:ftrl-vanila} is a direct analogue of
\eqref{equation:hedge-bound-2} for LEA.
A simple choice $\eta = 1/\sqrt{T}$ leads to an algorithm that satisfies
\begin{equation}
\label{equation:ftrl-vanila-2}
\Regret_T(u) \le \frac{1}{2}\left(1+\norm{u}^2\right)\sqrt{T} \; .
\end{equation}
However, this algorithm and the bound \eqref{equation:ftrl-vanila-2} have two
drawbacks.  First, the dependency on $\norm{u}$ is suboptimal. As we will see
shortly, the quadratic dependency can be replaced by an (almost) linear
dependency.  Second, the bound holds only for sequences of loss vectors with
$\norm{\ell_t} \le 1$, $t=1,2,\dots,T$. A robust algorithm should be able to
handle any sequence of loss vectors in $\H$.

Starting from \eqref{equation:ftrl-vanila}, if we choose learning rate $\eta =
D/\sqrt{T}$, we get a family of algorithms parametrized by $D \in [0,\infty)$
that satisfy an analogue of the bound \eqref{equation:hedge-bound-3}:
\begin{equation}
\label{equation:ftrl-vanila-3}
\forall u \in \H \qquad \norm{u} \le D \quad  \Longrightarrow \quad \Regret_T(u) \le D \sqrt{T} \; .
\end{equation}

Instead of family of algorithms parametrized by $D \in [0,\infty)$ satisfying
bound \eqref{equation:ftrl-vanila-3}, one \emph{would like
to have} a single algorithm (without any tuning parameters) satisfying
\begin{equation}
\label{equation:olo-parameter-free}
\forall u \in \H \qquad \Regret_T(u) \le \norm{u} \sqrt{T} \; .
\end{equation}
Bound \eqref{equation:olo-parameter-free} is an analogue of
\eqref{equation:parameter-free-bound-experts} for LEA. Similar to LEA,
\eqref{equation:olo-parameter-free} is stronger than
\eqref{equation:ftrl-vanila-3} in the following sense: A single algorithm
satisfying \eqref{equation:olo-parameter-free} implies
\eqref{equation:ftrl-vanila-3} for all values of $D \in [0,\infty)$.  However,
a family of algorithms $\{A_D : D \in [0,\infty)\}$ parametrized by $D$ where
$A_D$ satisfies \eqref{equation:ftrl-vanila-3}, does not yield a single
algorithm that satisfies \eqref{equation:olo-parameter-free}.  Finally, note
that \eqref{equation:olo-parameter-free} has better dependency on $\norm{u}$
than \eqref{equation:ftrl-vanila-2}.

Similar to LEA, there have been a lot of work on algorithms
\citep{Streeter-McMahan-2012, Orabona-2013, McMahan-Abernethy-2013,
McMahan-Orabona-2014} that satisfy a slightly weaker version of
\eqref{equation:olo-parameter-free}
\begin{equation}
\label{equation:olo-parameter-free-2}
\forall u \in \H \qquad \Regret_T(u) \le \big(O(1)+\polylog(1 + \norm{u})\norm{u} \big) \sqrt{T} \; ,
\end{equation}
where $\polylog(1 + \norm{u})$ represents a function that is upper bounded
by a polynomial in $\log(1+\norm{u})$.\footnote{It can be shown
that for OLO over Hilbert space the extra poly-logarithmic factor is
necessary~\citep{McMahan-Abernethy-2013,Orabona-2013}.} Algorithms satisfying
\eqref{equation:olo-parameter-free-2} are called \emph{parameter-free}, since
they do not need to know $D$.  Moreover, the bound
\eqref{equation:olo-parameter-free-2} has much better dependency on $\norm{u}$
than \eqref{equation:ftrl-vanila-2}.

Analogue of AdaHedge for OLO over Hilbert space is FTRL with adaptive learning
rate $\eta_t = 1/\sqrt{\sum_{i=1}^{t-1} \norm{\ell_i}^2}$.
\cite{Orabona-Pal-2015} (see also \cite{Orabona-Pal-2016-scale-free}) showed
that the resulting algorithm is scale-free and for any sequence of loss vectors
$\{\ell_t\}_{t=1}^\infty$, $\ell_t \in \H$, it satisfies
$$
\forall T \ge 0 \quad \forall u \in \H \qquad \Regret_T(u) \le \left(6.25 + \frac{1}{2}\norm{u}^2 \right) \sqrt{T} \max_{1 \le t \le T} \norm{\ell_t} \; .
$$
We stress that the algorithm does \emph{not} need to know $\max_{1 \le t \le T}
\norm{\ell_t}$.

Our second open problem is to design an algorithm that combines the advantages
of parameter-free and scale-free algorithms for OLO over a Hilbert space $\H$.
Formally: \emph{Construct an algorithm (without any tuning parameters) that
makes $O(1)$ vector operations in $\H$ and $O(1)$ other operations per round,
and satisfies for any sequence of loss vectors $\{\ell_t\}_{t=1}^\infty$,
$\ell_t \in \H$,}
$$
\forall T \ge 0 \ \ \forall u \in \H \ \ \Regret_T(u) \le \big(O(1)+\polylog(1 + \norm{u})\norm{u}\big)  \sqrt{\sum_{t=1}^{T} \norm{\ell_t}^2}.
$$
We offer \$100 USD for a positive solution of this problem.  Here $\polylog(1 +
\norm{u})$ represents a function that is upper bounded by a polynomial in
$\log(1+\norm{u})$ and $O(1)$ represents a universal constant.

The problem is interesting even for one-dimensional Hilbert space $\H = \R$.
Also, the reductions in \cite{Orabona-Pal-2016-parameter-free} implies that
solving the one-dimensional problem solves both the general Hilbert space and the
LEA cases.

Similar to LEA, attempts to solve the open problem included a doubling trick on
the maximum norm $\norm{\ell_t}$ seen so far. This approach fails the same way
as for LEA. Differently from the LEA case, running infinitely many copies of
FTRL and combining their predictions using AdaHedge with a non-uniform prior is
problematic because the predictions of the copies are not bounded. The open
problem for Hilbert space seems to be harder than the open problem than LEA,
and constructing even a computationally inefficient algorithm is an interesting
open problem.

\bibliography{biblio}

\end{document}
